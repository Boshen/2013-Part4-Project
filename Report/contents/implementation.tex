\chapter{Implementation Details} \label{chap:implementation}
The previous chapters have described all the algorithms that are considered for this project.
In this chapter, specific implementation details of the algorithms are discussed.

\section{Traffic assignment implementation}
Path equilibration algorithm and other algorithms for solving the traffic assignment problem have already been implemented by Olga Perederieieva, the co-supervisor of this project.
The algorithms are implemented in the C++ programming language.

The existing implementation of the path equilibration algorithm uses Bellman-Ford-Moore algorithm for its shortest path calculations as suggested by \citet{Sheffi}.
When solving the traffic assignment problem,
the algorithm spends most of its time computing shortest paths.
Significant amount of time is also spent on the convergence check step described in Section~\ref{sec:convergence},
where the algorithm requires to run the Bellman-Ford-Moore algorithm on all of the zones for the all-or-nothing solution.

\section{Graph storage}
To obtain information from the graph when running shortest path algorithms,
the storage of the underlying graph has been implemented in such a way that it can provide efficient access to its nodes and arcs.
The current implementation uses the Forward Star data structure described in \citet{Sheffi}.
The data structure compactly stores graphs in $O(|N|+|A|)$ spaces,
and provides $O(1)$ random access to all of its nodes,
it also provides $O(1)$ access to all out-going arcs of a randomly chosen node.
Using the Forward Star ensures the run time of accessing the graph can be neglected when analysing the shortest path algorithms.

\section{Priority queue implementations} \label{sec:pq_implementation}
As mentioned in Dijkstra's algorithm section (Section~\ref{sec:dijkstra}),
the performance of shortest path algorithms is heavily dependent on the implementation of the priority queue data structure.
Various priority queue implementations exist,
they include:
\begin{itemize}
    \item $\langle$priority\_queue$\rangle$ from the C++ standard template library,
    \item $\langle$set$\rangle$ from the C++ standard template library,
    \item $\langle$heap$\rangle$ from the C++ Boost library.
\end{itemize}
Here we use the angled brackets to denote the names are specific implementations of the priority queue data structure.

Each priority queue implementation has some advantages and disadvantages.
For example some provide faster tree balancing while others provide faster Extract-Min or Insert operation.
All of these implementations are studied for this project.

First we examine six variants of heap implementations from the C++ Boost $\langle$heap$\rangle$ library shown in Table~\ref{table:heaps}.
In the table, $N$ is the number of elements in the priority queue and
the time complexities are measured in amortized time.
Extract-Max and Increase-Key are referred as Extract-Min and Decrease-Key in Chapter~\ref{chap:solvingspp}.
Extract-Max and Increase-Key are used because
all Boost library heaps are implemented as max-heap trees,
elements are ordered from large to small in the tree so
the largest element is extracted first.
%\footnote{Amortized time gives how much time is taken in total when an operation is repeated a million times. For example with different inputs, run time is averaged between the worst-case and the best-case.}.

\begin{table}[!ht]
    \centering
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} l|ccccc}
                        & Insert    & Extract-Max      & Increase-Key \\ \midrule
        Binary          & $O(\log(N))$ & $O(\log(N))$ & $O(\log(N))$   \\
        Ternary         & $O(\log(N))$ & $O(\log(N))$ & $O(\log(N))$   \\
        Binomial        & $O(\log(N))$ & $O(\log(N))$ & $O(\log(N))$   \\
        Fibonacci       & $O(1)$      & $O(\log(N))$ & $O(1)$          \\
        Pairing         & $O(2^{2\log(\log(N))})$ & $O(\log(N))$ &  $O(2^{2\log(\log(N))})$ \\
        Skew            & $O(\log(N))$ & $O(\log(N))$ & $O(\log(N))$
    \end{tabular*}
    \caption{C++ Boost heap implementations with run time in amortized complexity \citep{BoostHeap}}
    \label{table:heaps}
\end{table}
Theories and analysis of these heap implementations can be found in \citet{Johnson1975} for Binary and Ternary, \citet{Vuillemin1978} for Binomial, \citet{Fredman} for Fibonacci, \citet{Fredman1986} for Pairing, and \citet{Sleator1986} for Skew.

We are interested in using Boost library heaps rather than the C++ standard template library heap due to one reason:
the Increase-Key operation.
The operation is used to change the distance labels in the priority queue when a node is scanned and updated during shortest path calculations.
In Dijkstra's algorithm,
nodes are often scanned multiple times in the label updating step,
so instead of adding the node again into the heap tree with a difference value,
we can use the Increase-Key operation to increase the value of the node's distance label.
The advantage of using this operation is that we can reduce the size of the heap tree, which results in a performance improvement as it takes less time to search and insert nodes to smaller heap trees.
Since Boost library heaps are max-heap trees,
all distance labels need to be negated when inserting them into the heap
in order for them be used in our shortest path algorithms.

In Table~\ref{table:heaps},
we observe that the Fibonacci heap has a very interesting time complexity.
It has a constant amortized $O(1)$ time for the Insert and Increase-Key operation.
This is very attractive for us,
but the problem is that we do not know how much constant time it really uses behind its big $O$ notation.

Next we examine $\langle$priority\_queue$\rangle$ from the C++ standard template library.
$\langle$priority\_queue$\rangle$ is implemented as binary min-heap tree.
It provides $O(\log(N))$ Insert and Extract-Min operation.
This implementation neither has the Decrease-Key operation nor a way to change node values or delete a node somewhere other than the top of the heap tree.
So when solving the shortest path problem,
the priority queue is going to contain the same nodes several times but with different distance labels.
This is not a problem for our shortest path algorithms.
When a node is added to the queue more than once with different distance labels,
the one with the smaller distance label is always going to be in front of the queue waiting to be extracted and labelled first,
so when that node is labelled,
all the other same nodes with larger distance labels in the queue will not affect finding the shortest path,
this is because the successors of those nodes have already been assigned with smaller distance labels.

Finally we examine $\langle$set$\rangle$ from the C++ standard template library.
A \emph{set} is a data structure used to store unique elements that follow a specific order.
In the C++ standard template library, it is implemented as a red-black binary search tree.
This data structure can be used for our shortest path algorithms because it provides $O(\log(N))$ insert, search and delete operations.
For our shortest path algorithms,
we can modify them to accommodate the unique elements and specific ordering requirement.
To meet the unique elements requirement,
instead of using the Increase-key operation whenever a node needs to be updated,
we simply delete that node and insert the one with the new value.
And for the ordering requirement,
we can just order the nodes non-decreasingly by their distance labels,
so the node with the minimum distance label always comes first.
The advantage of $\langle$set$\rangle$ compared to $\langle$priority\_queue$\rangle$ is that nodes can be removed from anywhere in the data structure,
since the performance of the operations is heavily dependent on the number of elements in the data structures.,
$\langle$set$\rangle$ can be faster than $\langle$priority\_queue$\rangle$ and require less memory compared to the other priority queues.

